{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fddc6c",
   "metadata": {},
   "source": [
    "# dask based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5835b-585d-41c3-acb7-190b55ddf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' dask based '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dtypes = {\"aggregation_year\": 'uint16', \"permanent_area\": 'float64',\n",
    "          \"seasonal_area\": 'float64',\n",
    "          \"maybepermanent\": 'float64',\n",
    "          \"maybeseasonal\": 'float64'\n",
    "         }\n",
    "\n",
    "data_dir =  Path('data')\n",
    "cols_required = ['permanent_area', \n",
    "                 # 'seasonal_area'\n",
    "                #  'maybepermanent', 'maybeseasonal'\n",
    "                ]\n",
    "\n",
    "arr_mean_std = []\n",
    "\n",
    "meta = {'id': 'str', 't_score': 'float', 'u_score': 'float', 'p_t': 'float', 'p_u': 'float', 'p_u_thd_0.01': 'bool'} #'id_bgl': 'object', 'start_year': int, 'basin_level': int\n",
    "meta_adm0 = {'id': 'str', 'adm0_name': 'str', 't_score': 'float', 'u_score': 'float', 'p_t': 'float', 'p_u': 'float', 'p_u_thd_0.01': 'bool'} #'id_bgl': 'object', 'start_year': int, 'basin_level': int\n",
    "# meta.update({col: 'float16' for col in cols_required})\n",
    "\n",
    "def t_test_and_u_test(group, p_thd = 0.01):\n",
    "    id = group.index[0] # basin_id\n",
    "    \n",
    "    patch = group[(group.index == id) & (group['aggregation_year']  >=2000)]\n",
    "    baseline_period = list(patch[patch['aggregation_year'] < 2020]['permanent_area'].values)\n",
    "    report_period = list(patch[patch['aggregation_year'] >= 2017]['permanent_area'].values)\n",
    "\n",
    "    # T-test\n",
    "    t_score, p_t = stats.ttest_ind(report_period, baseline_period)\n",
    "\n",
    "    # U-Test\n",
    "    u_score, p_u = stats.mannwhitneyu(report_period, baseline_period, equal_var=False)\n",
    "    median_report = np.median(report_period)\n",
    "    median_baseline = np.median(baseline_period)\n",
    "    median_diff = median_report - median_baseline\n",
    "    u_score = median_diff / np.abs(median_diff) * u_score\n",
    "\n",
    "    p_u_thd = float(p_u <= p_thd)\n",
    "\n",
    "    df = pd.DataFrame([[id, t_score, u_score, p_t, p_u, p_u_thd]], columns=['id', 't_score', 'u_score', 'p_t', 'p_u', 'p_u_thd_0.01'])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(dashboard_address=':38787')\n",
    "client = Client(cluster)#timeout\n",
    "\n",
    "for folder in [\"Pemanent_water\", \"Reservoirs\"]: # Reservoirs, Pemanent_water\n",
    "\n",
    "    output_dir = data_dir / f\"outputs_utest\" / folder\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    print(output_dir)\n",
    "\n",
    "    # basin-level analysis\n",
    "    # for basin_level in [0, 3, 4, 5, 6, 7, 8]:\n",
    "    for basin_level in [3]:\n",
    "        print()\n",
    "        print(f\"basins_level: {basin_level}\")\n",
    "    \n",
    "        url = data_dir / folder / f\"basins_level_{basin_level}_ts.csv\"\n",
    "        basin = dd.read_csv(url, include_path_column=False, dtype=dtypes).repartition(npartitions=80).set_index(f'id_bgl_{basin_level}')\n",
    "        \n",
    "        ''' for debug '''\n",
    "        # number = 31\n",
    "        # df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False)\n",
    "        # t_test_and_u_test(df_delta.get_group(\"112_262\").compute(), basin_level)\n",
    "    \n",
    "        # df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False).apply(calculate_delta, basin_level, epision, meta=meta)\n",
    "        df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False).apply(t_test_and_u_test, meta=meta).set_index('id')\n",
    "       \n",
    "        df_delta = df_delta.compute()\n",
    "        df_delta.to_csv(output_dir / f\"basins_level_{basin_level}_t_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8865d9f-157a-423a-a872-efdf4cbf37c3",
   "metadata": {},
   "source": [
    "# non-dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931904bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_utest\\Pemanent_water\n",
      "\n",
      "basins_level: 3\n",
      "outputs_utest\\Reservoirs\n",
      "\n",
      "basins_level: 3\n"
     ]
    }
   ],
   "source": [
    "''' non-dask '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dtypes = {\"aggregation_year\": 'uint16', \"permanent_area\": 'float64',\n",
    "          \"seasonal_area\": 'float64',\n",
    "          \"maybepermanent\": 'float64',\n",
    "          \"maybeseasonal\": 'float64'\n",
    "         }\n",
    "\n",
    "data_dir =  Path('data')\n",
    "cols_required = ['permanent_area', \n",
    "                 # 'seasonal_area'\n",
    "                #  'maybepermanent', 'maybeseasonal'\n",
    "                ]\n",
    "\n",
    "arr_mean_std = []\n",
    "\n",
    "meta = {'id': 'str', 't_score': 'float', 'u_score': 'float', 'p_t': 'float', 'p_u': 'float', 'p_u_thd_0.01': 'bool'} #'id_bgl': 'object', 'start_year': int, 'basin_level': int\n",
    "meta_adm0 = {'id': 'str', 'adm0_name': 'str', 't_score': 'float', 'u_score': 'float', 'p_t': 'float', 'p_u': 'float', 'p_u_thd_0.01': 'bool'} #'id_bgl': 'object', 'start_year': int, 'basin_level': int\n",
    "# meta.update({col: 'float16' for col in cols_required})\n",
    "\n",
    "def t_test_and_u_test(group, p_thd = 0.01):\n",
    "    id = group.index[0] # basin_id\n",
    "    \n",
    "    patch = group[(group.index == id) & (group['aggregation_year']  >=2000)]\n",
    "    baseline_period = list(patch[patch['aggregation_year'] < 2020]['permanent_area'].values)\n",
    "    report_period = list(patch[patch['aggregation_year'] >= 2017]['permanent_area'].values)\n",
    "\n",
    "    # T-test\n",
    "    t_score, p_t = stats.ttest_ind(report_period, baseline_period)\n",
    "\n",
    "    # U-Test\n",
    "    u_score, p_u = stats.mannwhitneyu(report_period, baseline_period)\n",
    "    median_report = np.median(report_period)\n",
    "    median_baseline = np.median(baseline_period)\n",
    "    median_diff = median_report - median_baseline\n",
    "    u_score = median_diff / np.abs(median_diff) * u_score\n",
    "\n",
    "    p_u_thd = float(p_u < p_thd)\n",
    "\n",
    "    df = pd.DataFrame([[id, t_score, u_score, p_t, p_u, p_u_thd]], columns=['id', 't_score', 'u_score', 'p_t', 'p_u', 'p_u_thd_0.01'])\n",
    "    return df\n",
    "\n",
    "for folder in [\"Pemanent_water\", \"Reservoirs\"]: # Reservoirs, Pemanent_water\n",
    "\n",
    "    output_dir = Path(\"outputs_utest\") / folder\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    print(output_dir)\n",
    "\n",
    "    # basin-level analysis\n",
    "    # for basin_level in [0, 3, 4, 5, 6, 7, 8]:\n",
    "    for basin_level in [3]:\n",
    "        print()\n",
    "        print(f\"basins_level: {basin_level}\")\n",
    "    \n",
    "        url = data_dir / folder / f\"basins_level_{basin_level}_ts.csv\"\n",
    "        basin = dd.read_csv(url, include_path_column=False, dtype=dtypes).repartition(npartitions=80).set_index(f'id_bgl_{basin_level}')\n",
    "        \n",
    "        ''' for debug '''\n",
    "        # number = 31\n",
    "        # df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False)\n",
    "        # t_test_and_u_test(df_delta.get_group(\"112_262\").compute(), basin_level)\n",
    "    \n",
    "        # df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False).apply(calculate_delta, basin_level, epision, meta=meta)\n",
    "        df_delta = basin.groupby(f'id_bgl_{basin_level}', group_keys=False).apply(t_test_and_u_test, meta=meta).set_index('id')\n",
    "       \n",
    "        df_delta = df_delta.compute()\n",
    "        df_delta.to_csv(output_dir / f\"basins_level_{basin_level}_utest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23011979-bdd1-40d9-af0a-ad56ae185624",
   "metadata": {},
   "source": [
    "# Abalysis on Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31c2ed-78db-457c-aba6-db226b3a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold\n",
    "def apply_threshold(input, thd_low, thd_high):\n",
    "    stb = input[(input['permanent_area'] >= thd_low) & (input['permanent_area'] <= thd_high)]\n",
    "    neg = input[(input['permanent_area'] < thd_low)]\n",
    "    pos = input[(input['permanent_area'] > thd_high)]\n",
    "    return neg, stb, pos\n",
    "\n",
    "\n",
    "data_dir = Path.home() / 'pz'\n",
    "ttest_dir = data_dir / \"outputs_ttest\"\n",
    "delta_dir = data_dir / \"outputs_delta\"\n",
    "\n",
    "folder = \"Reservoirs\" # Reservoirs\n",
    "basin_level = 4\n",
    "\n",
    "\n",
    "''' t-TEST and u-TEST '''\n",
    "# ttest = pd.read_csv(ttest_dir / folder / f\"basins_level_{basin_level}_ttest.csv\")\n",
    "\n",
    "''' Delta (2017)  '''\n",
    "# delta\n",
    "delta_all = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta.csv\")\n",
    "delta_2017 = delta_all[delta_all['start_year']==2017]\n",
    "total_num_basins = delta_2017.shape[0]\n",
    "print(f\"basin_level: {basin_level}, total number of basins: {total_num_basins}\")\n",
    "\n",
    "# mean and std\n",
    "df_muStd = pd.read_csv(delta_dir / folder / \"basin_level_mean_std.csv\").set_index('basin_level')\n",
    "mean = df_muStd['mean_permanent_area'][basin_level]\n",
    "std = df_muStd['std_permanent_area'][basin_level]\n",
    "print(f\"(all years), mean: {mean}, std: {std}\")\n",
    "\n",
    "# delta outliers removed\n",
    "delta_all_outliers_removed = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta_outliers_removed.csv\")\n",
    "delta_2017_rm = delta_all_outliers_removed[delta_all_outliers_removed['start_year']==2017]\n",
    "des_2017 = delta_2017_rm.describe()\n",
    "mean_2017 = des_2017.loc['mean', 'permanent_area']\n",
    "std_2017 = des_2017.loc['std', 'permanent_area']\n",
    "print(f\"(2017) mean: {mean_2017}, std: {std_2017}\")\n",
    "\n",
    "\n",
    "res_arr = []\n",
    "# for start_year in [2000, 2005, 2010, 2015, 2017]:\n",
    "start_year = 2017\n",
    "print()\n",
    "print(f'+++++++++++++++++++++++++++++++++ {start_year} ++++++++++++++++++++++++++++++++++')\n",
    "for alpha in [0.5, 1, 1.5, 2]:\n",
    "    print()\n",
    "    \n",
    "    print(f\"--------- apply all years thresholds (alpha = {alpha}) -----------\")\n",
    "    thd_high = mean + alpha * std\n",
    "    thd_low = mean - alpha * std\n",
    "    print(f\"(all years, alpha = {alpha}), [{thd_low}, {thd_high}]\")\n",
    "    neg, stb, pos = apply_threshold(delta_2017, thd_low, thd_high)\n",
    "    print(f\"neg: {neg.shape[0]}, stable: {stb.shape[0]}, pos: {pos.shape[0]}\")\n",
    "    print(f\"neg: {neg.shape[0] / total_num_basins * 100}, stable: {stb.shape[0] / total_num_basins * 100}, pos: {pos.shape[0] / total_num_basins * 100}\")\n",
    "    \n",
    "    print(f\"---------- apply 2017 thresholds (alpha = {alpha}) --------------\")\n",
    "    thr_2017_high = mean_2017 + alpha * std_2017\n",
    "    thr_2017_low = mean_2017 - alpha * std_2017\n",
    "    print(f\"(2017, alpha = {alpha}), [{thr_2017_low}, {thr_2017_high}]\")\n",
    "    neg_th17, stb_th17, pos_th17 = apply_threshold(delta_2017, thr_2017_low, thr_2017_high)\n",
    "    print(f\"neg: {neg_th17.shape[0]}, stable: {stb_th17.shape[0]}, pos: {pos_th17.shape[0]}\")\n",
    "    print(f\"neg: {neg_th17.shape[0] / total_num_basins * 100}, stable: {stb_th17.shape[0] / total_num_basins * 100}, pos: {pos_th17.shape[0] / total_num_basins * 100}\")\n",
    "\n",
    "        # [basin_level, num_basins, mean, std, aplha, thd_low, thd_high, neg.shape[0], stb.shape[0], pos.shape[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412af7f-7c8f-4dfd-9a3d-8ec7e2e09ae8",
   "metadata": {},
   "source": [
    "# Analysis on U-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44245cfa-d536-42bb-ac92-d7746b3b7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemanent_water\n",
      "reading: outputs_utest/Pemanent_water/basins_level_0_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_3_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_4_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_5_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_6_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_7_utest.csv\n",
      "reading: outputs_utest/Pemanent_water/basins_level_8_utest.csv\n",
      "Reservoirs\n",
      "reading: outputs_utest/Reservoirs/basins_level_0_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_3_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_4_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_5_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_6_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_7_utest.csv\n",
      "reading: outputs_utest/Reservoirs/basins_level_8_utest.csv\n"
     ]
    }
   ],
   "source": [
    "''' T-Test '''\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ttest_dir = Path(\"outputs_utest\")\n",
    "\n",
    "for folder in [\"Pemanent_water\", \"Reservoirs\"]: # Reservoirs, Pemanent_water\n",
    "    print(folder)\n",
    "    \n",
    "    res = []\n",
    "    p_thd_list = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05][::-1]\n",
    "    p_thd_cols = [f'p_thd_{p_thd}' for p_thd in p_thd_list]\n",
    "    for basin_level in [0, 3, 4, 5, 6, 7, 8]:\n",
    "        url = ttest_dir / folder / f\"basins_level_{basin_level}_utest.csv\"\n",
    "        print(f\"reading: {url}\")\n",
    "        ttest = pd.read_csv(url)\n",
    "        \n",
    "        num_change_list = []\n",
    "        for p_thd in p_thd_list:\n",
    "            # P-values close to 0 indicate that the observed difference is unlikely to be due to chance, (true difference?)\n",
    "            # whereas a P value close to 1 suggests no difference between the groups other than due to chance (no difference?)\n",
    "            num_basins = ttest.shape[0]\n",
    "            df_neg_pos = ttest[ttest['p_u'] <= p_thd]\n",
    "            neg = df_neg_pos[df_neg_pos['u_score'] < 0].shape[0]\n",
    "            pos = df_neg_pos[df_neg_pos['u_score'] > 0].shape[0]\n",
    "            stable = num_basins - neg - pos\n",
    "            \n",
    "            res.append([basin_level, num_basins, 2017, p_thd, neg, stable, pos])\n",
    "    \n",
    "    ttest_res = pd.DataFrame(res, columns=['basin_level', 'num_basins', 'start_year', 'p_u_thd', 'neg', 'stable', 'pos']).set_index('basin_level')\n",
    "    ttest_res.to_csv(ttest_dir / f'{folder}_utest_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a6035-6705-44bb-94d1-5d1ee12dd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Thresolding Delta with Mean and STD '''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# apply threshold\n",
    "def apply_threshold(input, thd_low, thd_high):\n",
    "    stb = input[(input['permanent_area'] >= thd_low) & (input['permanent_area'] <= thd_high)]\n",
    "    neg = input[(input['permanent_area'] < thd_low)]\n",
    "    pos = input[(input['permanent_area'] > thd_high)]\n",
    "    return neg, stb, pos\n",
    "\n",
    "data_dir = Path.home() / 'pz'\n",
    "ttest_dir = data_dir / \"outputs_ttest\"\n",
    "delta_dir = data_dir / \"outputs_delta\"\n",
    "\n",
    "folder = \"Reservoirs\" # Reservoirs, Pemanent_water\n",
    "\n",
    "''' Delta (2017)  '''\n",
    "res_arr = []\n",
    "for basin_level in [0, 3, 4, 5, 6, 7, 8]:\n",
    "    # delta\n",
    "    delta_all = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta.csv\")\n",
    "\n",
    "    # mean and std over all years\n",
    "    df_muStd = pd.read_csv(delta_dir / folder / \"basin_level_mean_std.csv\").set_index('basin_level')\n",
    "    mean = df_muStd['mean_permanent_area'][basin_level]\n",
    "    std = df_muStd['std_permanent_area'][basin_level]\n",
    "    print(f\"(all years), mean: {mean}, std: {std}\")\n",
    "    \n",
    "    # delta outliers removed\n",
    "    delta_all_outliers_removed = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta_outliers_removed.csv\")\n",
    "\n",
    "    for start_year in [2000, 2005, 2010, 2015, 2017]:\n",
    "    # for start_year in [2017]:\n",
    "        delta = delta_all[delta_all['start_year']==start_year]\n",
    "        num_basins = delta.shape[0]\n",
    "\n",
    "        # # delta outliers removed\n",
    "        # if start_year == 2017:\n",
    "        #     delta_rm = delta_all_outliers_removed[delta_all_outliers_removed['start_year']==start_year]\n",
    "        #     des_rm = delta_rm.describe()\n",
    "        #     mean = des_rm.loc['mean', 'permanent_area']\n",
    "        #     std = des_rm.loc['std', 'permanent_area']\n",
    "        #     print(f\"(start_year) mean: {mean}, std: {std}\")\n",
    "    \n",
    "        print()\n",
    "        print(f'+++++++++++++++++++++++++++++++++ basin_level: {basin_level}: {start_year} ++++++++++++++++++++++++++++++++++')\n",
    "        for alpha in [0.5, 1, 1.5, 2]:\n",
    "            print(f\"--------- apply all years thresholds (alpha = {alpha}) -----------\")\n",
    "            thd_high = mean + alpha * std\n",
    "            thd_low = mean - alpha * std\n",
    "            print(f\"(all years, alpha = {alpha}), [{thd_low}, {thd_high}]\")\n",
    "            neg, stb, pos = apply_threshold(delta, thd_low, thd_high)\n",
    "            print(f\"neg: {neg.shape[0]}, stable: {stb.shape[0]}, pos: {pos.shape[0]}\")\n",
    "            print(f\"neg: {neg.shape[0] / num_basins * 100}, stable: {stb.shape[0] / num_basins * 100}, pos: {pos.shape[0] / num_basins * 100}\")\n",
    "                \n",
    "            row = [basin_level, num_basins, start_year, mean, std, alpha, thd_low, thd_high, neg.shape[0], stb.shape[0], pos.shape[0]]\n",
    "            res_arr.append(row)\n",
    "\n",
    "col_names = ['basin_level', 'num_basins', 'start_year', 'mean', 'std', 'aplha', 'thd_low', 'thd_high', 'neg', 'stable', 'pos']\n",
    "df_res = pd.DataFrame(res_arr, columns=col_names)\n",
    "df_res.set_index('basin_level').to_csv(delta_dir / f\"{folder}_delta.csv\")\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bb1bd-4468-484a-b3ff-485f13a4666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Thresolding Delta with Mean and STD (2017) '''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# apply threshold\n",
    "def apply_threshold(input, thd_low, thd_high):\n",
    "    stb = input[(input['permanent_area'] >= thd_low) & (input['permanent_area'] <= thd_high)]\n",
    "    neg = input[(input['permanent_area'] < thd_low)]\n",
    "    pos = input[(input['permanent_area'] > thd_high)]\n",
    "    return neg, stb, pos\n",
    "\n",
    "data_dir = Path.home() / 'pz'\n",
    "ttest_dir = data_dir / \"outputs_ttest\"\n",
    "delta_dir = data_dir / \"outputs_delta\"\n",
    "\n",
    "for folder in [\"Reservoirs\", \"Pemanent_water\"]: # Reservoirs, Pemanent_water\n",
    "\n",
    "    ''' Delta (2017)  '''\n",
    "    res_arr = []\n",
    "    for basin_level in [0, 3, 4, 5, 6, 7, 8]:\n",
    "        # delta\n",
    "        delta_all = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta.csv\")\n",
    "    \n",
    "        # mean and std over all years\n",
    "        df_muStd = pd.read_csv(delta_dir / folder / \"basin_level_mean_std.csv\").set_index('basin_level')\n",
    "        mean = df_muStd['mean_permanent_area'][basin_level]\n",
    "        std = df_muStd['std_permanent_area'][basin_level]\n",
    "        print(f\"(all years), mean: {mean}, std: {std}\")\n",
    "        \n",
    "        # delta outliers removed\n",
    "        delta_all_outliers_removed = pd.read_csv(delta_dir / folder / f\"basins_level_{basin_level}_ts_delta_outliers_removed.csv\")\n",
    "    \n",
    "        # for start_year in [2000, 2005, 2010, 2015, 2017]:\n",
    "        for start_year in [2017]:\n",
    "            delta = delta_all[delta_all['start_year']==start_year]\n",
    "            num_basins = delta.shape[0]\n",
    "    \n",
    "            # # delta outliers removed\n",
    "            # if start_year == 2017:\n",
    "            #     delta_rm = delta_all_outliers_removed[delta_all_outliers_removed['start_year']==start_year]\n",
    "            #     des_rm = delta_rm.describe()\n",
    "            #     mean = des_rm.loc['mean', 'permanent_area']\n",
    "            #     std = des_rm.loc['std', 'permanent_area']\n",
    "            #     print(f\"(start_year) mean: {mean}, std: {std}\")\n",
    "        \n",
    "            print()\n",
    "            print(f'+++++++++++++++++++++++++++++++++ basin_level: {basin_level}: {start_year} ++++++++++++++++++++++++++++++++++')\n",
    "            for alpha in [0.5, 1, 1.5, 2, 2.5, 3, 4, 5]:\n",
    "                print(f\"--------- apply all years thresholds (alpha = {alpha}) -----------\")\n",
    "                thd_high = mean + alpha * std\n",
    "                thd_low = mean - alpha * std\n",
    "                print(f\"(all years, alpha = {alpha}), [{thd_low}, {thd_high}]\")\n",
    "                neg, stb, pos = apply_threshold(delta, thd_low, thd_high)\n",
    "                print(f\"neg: {neg.shape[0]}, stable: {stb.shape[0]}, pos: {pos.shape[0]}\")\n",
    "                print(f\"neg: {neg.shape[0] / num_basins * 100}, stable: {stb.shape[0] / num_basins * 100}, pos: {pos.shape[0] / num_basins * 100}\")\n",
    "                    \n",
    "                row = [basin_level, num_basins, start_year, mean, std, alpha, thd_low, thd_high, neg.shape[0], stb.shape[0], pos.shape[0]]\n",
    "                res_arr.append(row)\n",
    "    \n",
    "    col_names = ['basin_level', 'num_basins', 'start_year', 'mean', 'std', 'aplha', 'thd_low', 'thd_high', 'neg', 'stable', 'pos']\n",
    "    df_res = pd.DataFrame(res_arr, columns=col_names)\n",
    "    df_res.set_index('basin_level').to_csv(delta_dir / f\"{folder}_delta_2017_allThd.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39d317-17d6-402e-9fc1-7106bb83b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' T-Test '''\n",
    "\n",
    "data_dir = Path.home() / 'pz'\n",
    "ttest_dir = data_dir / \"outputs_ttest\"\n",
    "\n",
    "for folder in [\"Pemanent_water\", \"Reservoirs\"]: # Reservoirs, Pemanent_water\n",
    "    res = []\n",
    "    p_thd_list = [0.001, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "    p_thd_cols = [f'p_thd_{p_thd}' for p_thd in p_thd_list]\n",
    "    for basin_level in range(3, 9):\n",
    "        ttest = pd.read_csv(ttest_dir / folder / f\"basins_level_{basin_level}_t_test.csv\")\n",
    "        num_change_list = []\n",
    "        for p_thd in p_thd_list:\n",
    "            # P-values close to 0 indicate that the observed difference is unlikely to be due to chance, (true difference?)\n",
    "            # whereas a P value close to 1 suggests no difference between the groups other than due to chance (no difference?)\n",
    "            arr = ((ttest['p_t'] < p_thd).values | (ttest['p_u'] < p_thd).values).astype(float)\n",
    "            ttest[f'p_thd_{p_thd}'] = arr # True: different, False: no difference\n",
    "            num_change = int(arr.sum())\n",
    "            # print(f\"p_thd: {p_thd}, num of changes: {num_change}\")\n",
    "            num_change_list.append(num_change)\n",
    "        res.append([basin_level, 2017, ] + num_change_list)\n",
    "    \n",
    "    ttest_res = pd.DataFrame(res, columns=['basin_level', 'start_year'] + p_thd_cols).set_index('basin_level')\n",
    "    ttest_res.to_csv(ttest_dir / f'{folder}_ttest_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b955d-42c2-4bdb-9255-f74a15010c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11c9f2-33e1-4dd9-a80f-a3fc8a9017c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['basin_level'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a889de-0c26-4da4-9826-92773a789c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739af74-8a87-4d42-ab0e-4e0ddbca129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed54f7c-93fe-40a2-b50b-792c90cafeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ttest['p_t'] < p_thd).values & (ttest['p_t'] < p_thd).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e90235-a3f2-4bd8-884e-a1f7db133b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a656f7-93a8-41ca-8ff0-9e2ef1d28d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246486a-4357-4a68-8338-a26e0ed864fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897a4f9-f0da-4640-a859-a387ebdb131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = delta_2017_rm.describe().loc['mean', 'permanent_area']\n",
    "std = delta_2017_rm.describe().loc['std', 'permanent_area']\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0fa5c-3ee1-46f9-b306-b9c865c6ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "muStd['mean_permanent_area'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498cd03-562e-48e4-a78b-cadfb5e46c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Pemanent_water/basins_level_3_ts.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bca996-0c35-4e0c-a062-e3bf6dd51fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87fe8c-d6df-4b13-9a00-9f8389edf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa62b76-d76a-424c-ba34-257747a6af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e9c05-3ac6-4f78-89e4-63982e766918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9928e6-1156-4a30-b4fb-9fb8c318e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col].plot(kind='hist', logy=True, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b28af-7f8d-4099-a30d-978ff85554db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta['permanent_area'].dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa4621-4d4c-4333-809d-7e2f1cf894e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta['permanent_area'].dropna().describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
